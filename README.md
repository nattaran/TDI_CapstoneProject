# TDI_CapstoneProject
Sentiment classification regarding toxicity has been considered in the past few years, especially in the context of social media data. Keeping online conversations constructive and inclusive is a crucial task for platform providers. Automatic classification of toxic comments, such as hate speech, threats, and insults, can help in keeping discussions fruitful.
The goal of this project is to develop a multi-label model to identify different type of toxicity (toxic, severe-toxic, threat, obscene, insult and identity hate) in the text, which could then be used to stop users from posting harmful messages. 
I am going to use the dataset from Jigsaw/Googleâ€™s Toxic comment classification on Kaggle (https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/overview)

